{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "file_Path = r'Your file path!'\n",
    "# if you wanna use SQL:please alter the code\n",
    "URL_list = pd.read_excel(file_Path, sheet_name = 'your sheet name')['your columns'].to_list()\n",
    "\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:88.0) Gecko/20100101 Firefox/88.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.864.48 Safari/537.36 Edg/91.0.864.48\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.818.51 Safari/537.36 Edg/90.0.818.51\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.774.63 Safari/537.36 Edg/89.0.774.63\"\n",
    "]\n",
    "\n",
    "proxies = {\n",
    "    \"http\": \"socks5h://127.0.0.1:8443\",\n",
    "    \"https\": \"socks5h://127.0.0.1:8443\",\n",
    "}\n",
    "\n",
    "def get_soup(url, max_retries=3):\n",
    "    for _ in range(max_retries):\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': random.choice(USER_AGENTS),\n",
    "                'Accept-Language': 'en-US,en;q=0.9',\n",
    "                'Accept-Encoding': 'gzip, deflate, br',\n",
    "                'Referer': 'https://www.google.com/',\n",
    "                'Connection': 'keep-alive',\n",
    "            }\n",
    "            resp = requests.get(url=url, headers=headers, proxies=proxies)\n",
    "            return BeautifulSoup(resp.text, 'html.parser')\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "def process_url(url):\n",
    "    soup = get_soup(url)\n",
    "    if not soup:\n",
    "        return {\"sellerName\": \"-\", \"30daysRating\": \"-\", \"90daysRating\": \"-\", \"365daysRating\": \"-\", \"lifetimeRating\": \"-\",\n",
    "                \"reviews\": [], \"5starPercentage\": \"-\", \"4starPercentage\": \"-\", \"3starPercentage\": \"-\", \"2starPercentage\": \"-\", \"1starPercentage\": \"-\"}\n",
    "\n",
    "    sellerName = soup.find('h1', {'id': \"seller-name\"})\n",
    "    sellerName = sellerName.text.strip() if sellerName else \"-\"\n",
    "\n",
    "    sellerRating_30days = soup.find('span', {'id': \"effective-timeperiod-rating-thirty-description\"})\n",
    "    sellerRating_30days = sellerRating_30days.text.strip() if sellerRating_30days else \"-\"\n",
    "    sellerRating_90days = soup.find('span', {'id': \"effective-timeperiod-rating-ninety-description\"})\n",
    "    sellerRating_90days = sellerRating_90days.text.strip() if sellerRating_90days else \"-\"\n",
    "    sellerRating_365days = soup.find('span', {'id': \"effective-timeperiod-rating-year-description\"})\n",
    "    sellerRating_365days = sellerRating_365days.text.strip() if sellerRating_365days else \"-\"\n",
    "    sellerRating_lifeTime = soup.find('span', {'id': \"effective-timeperiod-rating-lifetime-description\"})\n",
    "    sellerRating_lifeTime = sellerRating_lifeTime.text.strip() if sellerRating_lifeTime else \"-\"\n",
    "\n",
    "    reviews = soup.find_all('span', {'id': \"-text\"})\n",
    "    reviewsList = [review.text.strip() for review in reviews] if reviews else []\n",
    "\n",
    "    rating_table = soup.find('table', {'id': 'ratingHistogram'})\n",
    "    if rating_table:\n",
    "        five_star_percent = rating_table.find('span', {'id': 'percentFiveStar'})\n",
    "        five_star_percent = five_star_percent.text.strip() if five_star_percent else \"-\"\n",
    "        four_star_percent = rating_table.find('span', {'id': 'percentFourStar'})\n",
    "        four_star_percent = four_star_percent.text.strip() if four_star_percent else \"-\"\n",
    "        three_star_percent = rating_table.find('span', {'id': 'percentThreeStar'})\n",
    "        three_star_percent = three_star_percent.text.strip() if three_star_percent else \"-\"\n",
    "        two_star_percent = rating_table.find('span', {'id': 'percentTwoStar'})\n",
    "        two_star_percent = two_star_percent.text.strip() if two_star_percent else \"-\"\n",
    "        one_star_percent = rating_table.find('span', {'id': 'percentOneStar'})\n",
    "        one_star_percent = one_star_percent.text.strip() if one_star_percent else \"-\"\n",
    "    else:\n",
    "        five_star_percent = four_star_percent = three_star_percent = two_star_percent = one_star_percent = \"-\"\n",
    "\n",
    "    return {\n",
    "        'seller': url,\n",
    "        \"sellerName\": sellerName,\n",
    "        \"30daysRating\": sellerRating_30days,\n",
    "        \"90daysRating\": sellerRating_90days,\n",
    "        \"365daysRating\": sellerRating_365days,\n",
    "        \"lifetimeRating\": sellerRating_lifeTime,\n",
    "        \"reviews\": reviewsList,\n",
    "        \"5starPercentage\": five_star_percent,\n",
    "        \"4starPercentage\": four_star_percent,\n",
    "        \"3starPercentage\": three_star_percent,\n",
    "        \"2starPercentage\": two_star_percent,\n",
    "        \"1starPercentage\": one_star_percent\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        future_to_url = {executor.submit(process_url, url): url for url in URL_list}\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                results[url] = data\n",
    "            except Exception as exc:\n",
    "                print(f\"{url} generated an exception: {exc}\")\n",
    "\n",
    "    # 确保结果按照 URL_list 的顺序\n",
    "    ordered_results = [results[url] for url in URL_list]\n",
    "    df = pd.DataFrame(ordered_results)\n",
    "    df.to_excel(r'your file path!')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
